{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draft code used to be in class MyLogger(Logger)'s __init()__ method\n",
    "# used to set up initial history keys\n",
    "num_output_layers = 6\n",
    "\n",
    "self.num_output_layers = num_output_layers\n",
    "        history_per_output_layer = {\n",
    "            # per epoch\n",
    "            'loss':[],\n",
    "            'acc':[],\n",
    "            'f1_score':[],\n",
    "            # these 2 will be replaced with step_y_pred and step_y_true respectively\n",
    "            'y_pred':[],\n",
    "            'y_true':[],\n",
    "        } \n",
    "\n",
    "def pre_suf_fix_dict(dict, fix_val='output_layer', prefix=True):\n",
    "    return {f\"{fix_val}_{key}\" if prefix else f\"{key}_{fix_val}\" : value for key, value in dict.items()}\n",
    "\n",
    "# to create val/test prefixed keys\n",
    "history_per_output_layer.update(\n",
    "    **pre_suf_fix_dict(history_per_output_layer, fix_val='val', prefix=True),\n",
    "    **pre_suf_fix_dict(history_per_output_layer, fix_val='test', prefix=True),\n",
    ")\n",
    "# to create step_ prefixed keys\n",
    "history_per_output_layer.update(\n",
    "    **pre_suf_fix_dict(history_per_output_layer, fix_val='step', prefix=True),\n",
    ")\n",
    "# removing y_pred, y_true and keeping step_y_pred and step_y_true\n",
    "history_per_output_layer.pop('y_pred')\n",
    "history_per_output_layer.pop('y_true')\n",
    "\n",
    "# fix_val == suffix without \"_\"; to provide flexibility in using fix_val as prefix as well (if we wanted to!)\n",
    "self.out_layers_fix_val = 'output_layer' \n",
    "\n",
    "# pre_suf_fix_dict function is used to create unique key names to merge the `num_output_layers` histories into one history dictionary\n",
    "history_ol_lists = [pre_suf_fix_dict(history_per_output_layer, \n",
    "                                    fix_val=f'{self.out_layers_fix_val}_{i}', \n",
    "                                    prefix=False) \n",
    "                    for i in range(self.num_output_layers)] # ol == output layers\n",
    "\n",
    "# 'loss' here is for the final loss calculated by the loss aggregator function which uses all `num_output_layers` losses\n",
    "self.history = {'loss':[], 'val_loss':[], 'test_loss':[]}\n",
    "self.history.update(**pre_suf_fix_dict(self.history, 'step', prefix=True))\n",
    "# merging the `num_output_layers` histories into one history dictionary\n",
    "for hist_dict in history_ol_lists:\n",
    "    self.history.update(**hist_dict)\n",
    "\n",
    "self.hist_keys = list(self.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed manual logging\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "import torchmetrics\n",
    "\n",
    "class HierarchalModelPL(pl.LightningModule):\n",
    "   def __init__(self, hierarchical_model, num_classes_per_layer:list, loss_weights=None, dummy_input_size=(32, 3, 306, 306), the_device='cpu'):\n",
    "      super(HierarchalModelPL, self).__init__()\n",
    "      self.hierarchical_model = hierarchical_model # .to(the_device)\n",
    "      self.num_output_layers = len(num_classes_per_layer)\n",
    "      self.loss_weights = [1]*self.num_output_layers if loss_weights is None else loss_weights\n",
    "      self.num_output_layers = self.num_output_layers\n",
    "      \n",
    "      # useful for writing computational graph in tensorboard, summary(), etc\n",
    "      self.example_input_array = torch.randn(*dummy_input_size) # , device=the_device\n",
    "\n",
    "      self.the_device = the_device if 'cpu' in the_device else 'cuda'\n",
    "      self.metrics = ['acc', 'f1_score']\n",
    "      def _create_metric_func(metric_type:str, num_classes):\n",
    "         if 'acc' in metric_type.lower():\n",
    "               return torchmetrics.Accuracy(task='multiclass', \n",
    "                                          num_classes=num_classes, \n",
    "                                          average=\"micro\").to(the_device)\n",
    "         elif 'f1' in metric_type.lower():\n",
    "               return torchmetrics.F1Score(task=\"multiclass\", \n",
    "                                          num_classes=num_classes, \n",
    "                                          average=None).to(the_device)\n",
    "      \n",
    "      #                                         step/epoch vvv\n",
    "      # max indexing possible: self.metric_funcs['f1_score'][1][num_output_layers-1][2]\n",
    "      #                                       softmax output layers ^^^            ^^^  train/val/test \n",
    "      # output example of metric_funcs['acc']\n",
    "      # (note: MCA == MulticlassAccuracy()):\n",
    "      # {'acc': [ \n",
    "      #   [ #step\n",
    "      #    [MCA, MCA, MCA], # softmax_output_layer_0 ; train/val/test\n",
    "      #    [MCA, MCA, MCA],\n",
    "      #    [MCA, MCA, MCA], # ...\n",
    "      #    [MCA, MCA, MCA],\n",
    "      #    [MCA, MCA, MCA],\n",
    "      #    [MCA, MCA, MCA] # # softmax_output_layer_5 ; train/val/test\n",
    "      #   ],\n",
    "      #   [ #epoch\n",
    "      #    [MCA, MCA, MCA],\n",
    "      #    [MCA, MCA, MCA],\n",
    "      #    [MCA, MCA, MCA],\n",
    "      #    [MCA, MCA, MCA],\n",
    "      #    [MCA, MCA, MCA],\n",
    "      #    [MCA, MCA, MCA]\n",
    "      #   ]\n",
    "      # ]\n",
    "      \n",
    "      self.metric_funcs = {}\n",
    "      for metric in self.metrics:\n",
    "         # i --> step/epoch, j --> num_output_layers-1, k --> train/val/test\n",
    "         self.metric_funcs[metric] = [[[_create_metric_func(metric, num_classes_per_layer[j]) for k in range(3)] \n",
    "                                       for j in range(self.num_output_layers)] \n",
    "                                       for i in range(2)]\n",
    "      \n",
    "      # fix_val == suffix without \"_\"; to provide flexibility in using fix_val as prefix as well (if we wanted to!)\n",
    "      self.history_layers_fix_val = 'output_layer' \n",
    "\n",
    "\n",
    "   def forward(self, x):\n",
    "      # len(hier_y_probs) == num_hierarchy_output_layers, \n",
    "      # while each element is 2D tensor of shape (batch_size, num_classes of the i_th output layer in hierarchy)\n",
    "      hier_y_pred = []\n",
    "      for tensor_output in self.hierarchical_model(x):\n",
    "         hier_y_pred.append(F.softmax(tensor_output, dim=1))\n",
    "      hier_y_pred\n",
    "      return hier_y_pred\n",
    "   \n",
    "   def training_step(self, batch, batch_idx):\n",
    "      ds_prefix = ''\n",
    "      metrics_dict = self._step_logic(batch, ds_prefix=ds_prefix)\n",
    "      # add other key:value pairs here or pass the entire metrics_dict if you want. just make sure 'loss' key is present\n",
    "      return metrics_dict\n",
    "    \n",
    "   def training_epoch_end(self, outputs) -> None:\n",
    "      # 'outputs' argument here contains values from what was returned from training_step()\n",
    "      ds_prefix = ''\n",
    "      self._epoch_end_logic(outputs, ds_prefix)\n",
    "\n",
    "   def validation_step(self, batch, batch_idx):\n",
    "      ds_prefix = 'val_'\n",
    "      metrics_dict = self._step_logic(batch, ds_prefix=ds_prefix)\n",
    "      return metrics_dict\n",
    "   \n",
    "   def validation_epoch_end(self, outputs) -> None:\n",
    "      ds_prefix = 'val_'\n",
    "      self._epoch_end_logic(outputs, ds_prefix)\n",
    "   \n",
    "   def test_step(self, batch, batch_idx):\n",
    "      ds_prefix = 'test_'\n",
    "      metrics_dict = self._step_logic(batch, ds_prefix=ds_prefix)\n",
    "      return metrics_dict\n",
    "   \n",
    "   def test_epoch_end(self, outputs) -> None:\n",
    "      ds_prefix = 'test_'\n",
    "      self._epoch_end_logic(outputs, ds_prefix=ds_prefix)\n",
    "   \n",
    "\n",
    "   def _store_metric(self, metric_name, metric_val):\n",
    "      self.logger.log(metric_name, metric_val)\n",
    "      # try:\n",
    "      #    self.log(metric_name, metric_val)\n",
    "      # except Exception:\n",
    "      #    # then metric_val is not scalar, then this means:\n",
    "      #    # metric_name is an f1 score metric \n",
    "      #    # so, we just take the mean value\n",
    "      #    self.log(metric_name, metric_val.mean())\n",
    "      # # putting this here ensures we don't include the mean of f1 score, \n",
    "      # # but rather the tensor of shape (1, num_classes)\n",
    "\n",
    "   def _step_logic(self, batch, ds_prefix=''):\n",
    "      # ds_prefix == dataset_prefix\n",
    "      if 'val' in ds_prefix:\n",
    "         ds_type_idx = 1\n",
    "      elif 'test' in ds_prefix:\n",
    "         ds_type_idx = 2\n",
    "      else:\n",
    "         ds_type_idx = 0\n",
    "      ds_prefix = 'step_' + ds_prefix\n",
    "\n",
    "      x, y = batch\n",
    "      hier_y_pred = self(x)\n",
    "\n",
    "      # y now has shape (batch_size, len(hier_y_pred))\n",
    "      # in other words, each row now consists of `len(hier_y_pred)` output layers' labels of 1 sample\n",
    "      # side note: len(hier_y_pred) == self.num_output_layers\n",
    "      y = torch.tensor([labelToHierarchy[int(y[i])] for i in range(len(y))], dtype=int, device=self.the_device) # alternatively, range(y.size()[0])\n",
    "      # transpose y to take each row (batch of labels) with its corresponding hier_y_pred row (batch of predicted labels)\n",
    "      # in other words, each row now consists of `batch_size` labels of the i_th output layer\n",
    "      y = y.T\n",
    "      # softmax_output_layer elements each has shape (batch_size, num_classes of the i_th output layer in hierarchy)\n",
    "      # side note: the wording of \"i_th output layers\" refers to the strings mentioned in \n",
    "      # output_order argument of HierarchalModel() used in create_hnn_model_arch()\n",
    "\n",
    "      losses_dict = {}\n",
    "      other_metrics_dict = {}\n",
    "      for out_layer_idx, softmax_output_layer in enumerate(hier_y_pred): \n",
    "         # 'cur' refers to current output layer\n",
    "         y_cur = y[out_layer_idx]\n",
    "         y_pred_cur = softmax_output_layer.to(self.the_device)\n",
    "         ol_suffix = f'_{self.history_layers_fix_val}_{out_layer_idx}'\n",
    "\n",
    "         # log step metrics\n",
    "\n",
    "         loss = F.cross_entropy(y_pred_cur, y_cur)\n",
    "         loss_full_metric_name = f'{ds_prefix}loss{ol_suffix}'\n",
    "         self._store_metric(loss_full_metric_name, loss)\n",
    "         losses_dict[loss_full_metric_name] = loss\n",
    "\n",
    "         for metric_name in self.metrics:\n",
    "            # recall the indexing of self.metric_funcs:\n",
    "            # metric_name, step/epoch, num_output_layers-1, train/val/test\n",
    "            metric_val = self.metric_funcs[metric_name][0][out_layer_idx][ds_type_idx](y_pred_cur, y_cur)\n",
    "            full_metric_name = f'{ds_prefix}{metric_name}{ol_suffix}'\n",
    "            self._store_metric(full_metric_name, metric_val)\n",
    "            self.metric_funcs[metric_name][1][out_layer_idx][ds_type_idx].update(y_pred_cur, y_cur)\n",
    "            other_metrics_dict[full_metric_name] = metric_val\n",
    "      \n",
    "         f1_score = self.metric_funcs[metric_name][0][out_layer_idx][ds_type_idx](y_pred_cur, y_cur)\n",
    "         self._store_metric(f'{ds_prefix}{metric_name}{ol_suffix}', f1_score)\n",
    "         self.metric_funcs[metric_name][1][out_layer_idx][ds_type_idx].update(y_pred_cur, y_cur)\n",
    "\n",
    "         # storing y_pred/y_true\n",
    "         # self.history[f'{ds_prefix}y_pred{ol_suffix}'].extend(y_pred_cur)\n",
    "         # self.history[f'{ds_prefix}y_true{ol_suffix}'].extend(y_cur)\n",
    "\n",
    "      final_loss = self.metric_reduce_fx(losses_dict.values(), 'weighted_sum')\n",
    "      self._store_metric(f'{ds_prefix}loss', final_loss)\n",
    "\n",
    "      # Important note: 'loss' key must be present, or else you'll get this error:\n",
    "      # MisconfigurationException: In automatic_optimization, \n",
    "      # when `training_step` returns a dict, the 'loss' key needs to be present\n",
    "      # side note: add `.update(losses_dict)` and `.update(other_metrics_dict)` \n",
    "      # if you want to directly use other metrics in \"..._epoch_end()\" methods\n",
    "      return {f'loss' : final_loss} \n",
    "\n",
    "   def _epoch_end_logic(self, outputs, ds_prefix=''):\n",
    "      if 'val' in ds_prefix:\n",
    "         ds_type_idx = 1\n",
    "      elif 'test' in ds_prefix:\n",
    "         ds_type_idx = 2\n",
    "      else:\n",
    "         ds_type_idx = 0\n",
    "\n",
    "      # log epoch metrics\n",
    "      final_loss_epoch = torch.tensor([x[f'loss'] for x in outputs], dtype=float).mean()\n",
    "      self._store_metric(f'{ds_prefix}loss', final_loss_epoch)\n",
    "\n",
    "      for out_layer_idx in range(self.num_output_layers):\n",
    "         ol_suffix = f'_{self.history_layers_fix_val}_{out_layer_idx}'\n",
    "\n",
    "         for metric_name in self.metrics:\n",
    "            # recall: '1' for accessing epoch func (not step func)\n",
    "            metric_val_epoch = self.metric_funcs[metric_name][1][out_layer_idx][ds_type_idx].compute()\n",
    "            self.metric_funcs[metric_name][1][out_layer_idx][ds_type_idx].reset()\n",
    "            full_metric_name = f'{ds_prefix}{metric_name}{ol_suffix}'\n",
    "            self._store_metric(full_metric_name, metric_val_epoch)\n",
    "            if out_layer_idx == 0:\n",
    "               print(metric_name)\n",
    "               print(metric_val_epoch)\n",
    "               print()\n",
    "   \n",
    "   def metric_reduce_fx(self, metric_list, agg_type='weighted_sum'):\n",
    "      '''\n",
    "      aggregates metric values from all `num_output_layers` into a single value\n",
    "      side note: called \"reduce_fx\" as a reference to PyTorch Lightning's reduce_fx parameter found in self.log()\n",
    "      '''\n",
    "      if 'weighted' in agg_type.lower() and 'sum' in agg_type.lower():\n",
    "         weighted_sum_val = 0\n",
    "         for i, layer_metric_val in enumerate(metric_list):\n",
    "            weighted_sum_val += self.loss_weights[i] * layer_metric_val\n",
    "         final_val = weighted_sum_val\n",
    "\n",
    "      return final_val\n",
    "\n",
    "   def configure_optimizers(self):\n",
    "      # make it self.hierarchical_model.parameters() if you defined other parameters in __init()__ which you don't want to optimize\n",
    "      # side note: under the hood, pl automatically gets gradients \n",
    "      # from final_loss returned from training_step() and adjusts the models' branches accordingly\n",
    "      # source: https://github.com/Lightning-AI/lightning/issues/2645#issuecomment-660681760\n",
    "      return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
