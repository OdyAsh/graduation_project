{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Metadata Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_exif_orientation(image_data_np):\n",
    "    # Extract the EXIF metadata from the image\n",
    "    with open('example.jpg', 'rb') as f:\n",
    "        exif_data = exifread.process_file(f)\n",
    "    # Check if the Orientation tag is present in the metadata\n",
    "    if 'Image Orientation' in exif_data:\n",
    "        # Get the orientation value from the metadata\n",
    "        orientation = exif_data['Image Orientation'].values[0]\n",
    "        # Apply the appropriate rotation or flip operation to the image data\n",
    "        if orientation == 0 or orientation == 1:\n",
    "            # Normal orientation (no rotation or flip needed)\n",
    "            corrected_image_np = image_data_np\n",
    "        elif orientation == 2:\n",
    "            # Flip horizontally\n",
    "            corrected_image_np = np.fliplr(image_data_np)\n",
    "        elif orientation == 3:\n",
    "            # Rotate 180 degrees\n",
    "            corrected_image_np = np.rot90(image_data_np, k=2)\n",
    "        elif orientation == 4:\n",
    "            # Flip vertically\n",
    "            corrected_image_np = np.flipud(image_data_np)\n",
    "        elif orientation == 5:\n",
    "            # Flip horizontally and rotate 270 degrees clockwise\n",
    "            corrected_image_np = np.rot90(np.fliplr(image_data_np), k=3)\n",
    "        elif orientation == 6:\n",
    "            # Rotate 270 degrees clockwise\n",
    "            corrected_image_np = np.rot90(image_data_np, k=3)\n",
    "        elif orientation == 7:\n",
    "            # Flip horizontally and rotate 90 degrees clockwise\n",
    "            corrected_image_np = np.rot90(np.fliplr(image_data_np), k=1)\n",
    "        elif orientation == 8:\n",
    "            # Rotate 90 degrees clockwise\n",
    "            corrected_image_np = np.rot90(image_data_np, k=1)\n",
    "    else:\n",
    "        # No orientation tag found, use the original image data\n",
    "        corrected_image_np = image_data_np\n",
    "    return corrected_image_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/82. academicDigital\\20191030_184108.jpg\n",
      "./dataset/82. academicDigital\\IMG-20191220-WA0015.jpg\n",
      "./dataset/82. academicDigital\\IMG-20191221-WA0002.jpg\n",
      "./dataset/82. academicDigital\\thumbnail_14.jpg\n",
      "./dataset/82. academicDigital\\thumbnail_164.jpg\n",
      "./dataset/82. academicDigital\\thumbnail_206.jpg\n",
      "./dataset/82. academicDigital\\thumbnail_207.jpg\n",
      "./dataset/82. academicDigital\\thumbnail_208.jpg\n",
      "./dataset/82. academicDigital\\thumbnail_210.jpg\n",
      "./dataset/82. academicDigital\\thumbnail_211.jpg\n",
      "./dataset/82. academicDigital\\thumbnail_213.jpg\n",
      "./dataset/82. academicDigital\\thumbnail_214.jpg\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "image_files = glob.glob('./dataset/82. academicDigital/*.jpg')\n",
    "i = 0\n",
    "for path in image_files:\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            exif_tags = exifread.process_file(f, details=False)\n",
    "            if len(exif_tags) == 0:\n",
    "                continue\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    for tag in exif_tags.keys():\n",
    "        print(path)\n",
    "        i += 1\n",
    "        break\n",
    "        # print(f\"{tag}: {exif_tags[tag]}\")\n",
    "    # print()\n",
    "    # print()\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open('dataset_phone_preview/image.jpg')\n",
    "width, height = img.size\n",
    "resolution = str(width) + 'x' + str(height)\n",
    "\n",
    "import imghdr\n",
    "\n",
    "format = imghdr.what('dataset_phone_preview/image.jpg')\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "\n",
    "exif_data = img._getexif()\n",
    "\n",
    "for tag, value in exif_data.items():\n",
    "    tag_name = TAGS.get(tag, tag)\n",
    "    if tag_name == 'DateTimeOriginal':\n",
    "        date_time = value\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "exif_data = img._getexif()\n",
    "\n",
    "for tag, value in exif_data.items():\n",
    "    tag_name = TAGS.get(tag, tag)\n",
    "    if tag_name == 'GPSInfo':\n",
    "        lat = value[2]\n",
    "        lon = value[4]\n",
    "        lat_ref = value[1]\n",
    "        lon_ref = value[3]\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "metadata = img.info.get('keywords')\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "color_profile = img.info.get('icc_profile')\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "exif_data = img._getexif()\n",
    "\n",
    "camera_settings  ={}\n",
    "for tag, value in exif_data.items():\n",
    "    tag_name = TAGS.get(tag, tag)\n",
    "    if tag_name in ['ExposureTime', 'FNumber', 'ISOSpeedRatings']:\n",
    "        camera_settings[tag_name] = value\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('dataset_phone_preview/image.jpg')\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "faces_list = []\n",
    "for (x,y,w,h) in faces:\n",
    "    faces_list.append([x,y,w,h])\n",
    "\n",
    "print(width, height, resolution)\n",
    "print(exif_data)\n",
    "print(date_time)\n",
    "print(metadata)\n",
    "print(color_profile)\n",
    "print(camera_settings)\n",
    "print(faces_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draft, to do: delete later, this was for detecting text bounding boxes quickly\n",
    "\n",
    "# Load the image\n",
    "img = Image.open('./dataset/20. ememes/ememes0002155.jpg')\n",
    "img = img.resize((306,306))\n",
    "img = np.array(img)\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Apply thresholding to segment the text\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours in the image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterate through the contours and draw bounding boxes around the text\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# # Display the output image\n",
    "# cv2.imshow('Text Detection', img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
