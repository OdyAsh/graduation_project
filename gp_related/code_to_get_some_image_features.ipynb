{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open('dataset_phone_preview/image.jpg')\n",
    "width, height = img.size\n",
    "resolution = str(width) + 'x' + str(height)\n",
    "\n",
    "import imghdr\n",
    "\n",
    "format = imghdr.what('dataset_phone_preview/image.jpg')\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "\n",
    "exif_data = img._getexif()\n",
    "\n",
    "for tag, value in exif_data.items():\n",
    "    tag_name = TAGS.get(tag, tag)\n",
    "    if tag_name == 'DateTimeOriginal':\n",
    "        date_time = value\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "exif_data = img._getexif()\n",
    "\n",
    "for tag, value in exif_data.items():\n",
    "    tag_name = TAGS.get(tag, tag)\n",
    "    if tag_name == 'GPSInfo':\n",
    "        lat = value[2]\n",
    "        lon = value[4]\n",
    "        lat_ref = value[1]\n",
    "        lon_ref = value[3]\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "metadata = img.info.get('keywords')\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "color_profile = img.info.get('icc_profile')\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "exif_data = img._getexif()\n",
    "\n",
    "camera_settings  ={}\n",
    "for tag, value in exif_data.items():\n",
    "    tag_name = TAGS.get(tag, tag)\n",
    "    if tag_name in ['ExposureTime', 'FNumber', 'ISOSpeedRatings']:\n",
    "        camera_settings[tag_name] = value\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('dataset_phone_preview/image.jpg')\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "faces_list = []\n",
    "for (x,y,w,h) in faces:\n",
    "    faces_list.append([x,y,w,h])\n",
    "\n",
    "print(width, height, resolution)\n",
    "print(exif_data)\n",
    "print(date_time)\n",
    "print(metadata)\n",
    "print(color_profile)\n",
    "print(camera_settings)\n",
    "print(faces_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draft, to do: delete later, this was for detecting text bounding boxes quickly\n",
    "\n",
    "# Load the image\n",
    "img = Image.open('./dataset/20. ememes/ememes0002155.jpg')\n",
    "img = img.resize((306,306))\n",
    "img = np.array(img)\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Apply thresholding to segment the text\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Find contours in the image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterate through the contours and draw bounding boxes around the text\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# # Display the output image\n",
    "# cv2.imshow('Text Detection', img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
