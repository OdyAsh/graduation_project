{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hnn_model_arch(model_version:str, img_size:tuple, class_groups:dict, classes:dict, hierarchy:dict):\n",
    "    base_model = nn.Sequential(\n",
    "        # note that padding is 0 to re-produce TF's implementation of m01, where the default value for 'padding' argument is 'valid' which means no padding\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=0), \n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        # deviated from TF implementation of m01 by making this 1024 instead of 512\n",
    "        nn.LazyLinear(1024),\n",
    "        nn.ReLU(),\n",
    "        # unlike TF implementation of m01, we'll not include this layer here, rather we'll add it later\n",
    "        # nn.Softmax(dim=1) \n",
    "    )\n",
    "\n",
    "    # these are the indepdent layers of parent and children\n",
    "    model_layers = [\n",
    "        # the output of this layer is feed forward from parent to child\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.Linear(128, 64),\n",
    "        # we do not include the layer below, as it is automatically created at the end of each parent/child. check this for details:\n",
    "        # https://github.com/rajivsarvepalli/SimpleHierarchy/blob/8e4c29f334928f43509b2d328b11b4a83f2d2af6/src/simple_hierarchy/hierarchal_model.py#L173\n",
    "        # nn.Linear(64, num_classes), \n",
    "    ]\n",
    "\n",
    "    # 1024 is the output size of our base model\n",
    "    # 1024 is the input size of our additional indepdent layers (called model_layers)\n",
    "    # 64 is the output size of our additional indepdent layers (called model_layers) (excluding the final automatically-created hidden layer)\n",
    "    # 512 is the output size of fourth to last additional indepdent layer to feed (note: we say 'third to last' if we neglect talking about the final automatically-created hidden layer)\n",
    "    # forward from parent to child (with concatenation)\n",
    "    size = (1024,1024,64,512)\n",
    "    # all 4 layers are distinct for each grouping of classes of model_layers (actually 5 layers if you add the automatically-created hidden layer)\n",
    "    k = 4\n",
    "    # we want to feed from the fourth to last layer (from parent to child (with concatenation)) (note: we say 'third to last' if we neglect talking about the final automatically-created hidden layer)\n",
    "    feed_from = 3\n",
    "    output_order = [*class_groups.values()]\n",
    "    idx_to_class_name = {k : v for k, v in enumerate([*class_groups.keys(), *classes.keys()])}\n",
    "    model = DemoModel(hierarchy, base_model, size, model_layers, k, feed_from, output_order)\n",
    "    \n",
    "    a = torch.rand(3,*img_size).unsqueeze(0)\n",
    "    # running an arbitrary forward pass to initialze weights/params (since LazyLinear was used)\n",
    "    model(a) \n",
    "\n",
    "    writer = SummaryWriter(f\"./models/hnn_model_v{model_version}_tb_graphs\")\n",
    "    writer.add_graph(model, a)\n",
    "    writer.close()\n",
    "\n",
    "    return model, idx_to_class_name\n",
    "# Example input\n",
    "img_size = (306,306)\n",
    "demo_model, idx_to_class_name = create_hnn_model_arch(\"03\", img_size, cgs, cs, hierarchy)\n",
    "a = torch.rand(3,*img_size).unsqueeze(0)\n",
    "demo_model(a)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
