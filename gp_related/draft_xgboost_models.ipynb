{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model on used m01.1 CNN Model, Original Dataset with no Metadata, All Batch Size, and 100 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00. selfies              0.3220071816091017       \n",
      "50. fTxtMssgs            0.9869636293589062       \n",
      "70. eGreetingAndMisc     1.1198180636777129       \n",
      "81. academicPhotos       2.461296772350757        \n",
      "10. fmemes               0.4838910585292391       \n",
      "20. ememes               1.1225633008834885       \n",
      "30. fSocialMedia         5.572427983539095        \n",
      "82. academicDigital      7.732664382444118        \n",
      "40. eSocialMedia         3.1665330393532436       \n"
     ]
    }
   ],
   "source": [
    "# debugging\n",
    "# classes_weights = class_weight.compute_sample_weight(\n",
    "#     class_weight='balanced',\n",
    "#     y=y_train\n",
    "# )\n",
    "# un_list = []\n",
    "# un_labels = []\n",
    "# for i, a_label in enumerate(y_train):\n",
    "#     if a_label not in un_labels:\n",
    "#         un_labels.append(a_label)\n",
    "#         un_list.append(classes_weights[i])\n",
    "# numToClassName = {value: key for key, value in classNameToNum.items()}\n",
    "# for i in range(len(un_labels)):\n",
    "#     print(f\"{numToClassName[un_labels[i]]:<25}{un_list[i]:<25}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.13378\ttrain-mlogloss:1.34860\ttrain-f1_score:0.81785\tval-merror:0.24383\tval-mlogloss:1.47916\tval-f1_score:0.72606\n",
      "[1]\ttrain-merror:0.10826\ttrain-mlogloss:1.04273\ttrain-f1_score:0.86092\tval-merror:0.22793\tval-mlogloss:1.21828\tval-f1_score:0.75284\n",
      "[2]\ttrain-merror:0.09552\ttrain-mlogloss:0.84429\ttrain-f1_score:0.87976\tval-merror:0.21643\tval-mlogloss:1.05092\tval-f1_score:0.76749\n",
      "[3]\ttrain-merror:0.08579\ttrain-mlogloss:0.70102\ttrain-f1_score:0.89029\tval-merror:0.21233\tval-mlogloss:0.93309\tval-f1_score:0.77259\n",
      "[4]\ttrain-merror:0.07913\ttrain-mlogloss:0.59435\ttrain-f1_score:0.89850\tval-merror:0.20817\tval-mlogloss:0.84649\tval-f1_score:0.77803\n",
      "[5]\ttrain-merror:0.07153\ttrain-mlogloss:0.50963\ttrain-f1_score:0.90834\tval-merror:0.19882\tval-mlogloss:0.77721\tval-f1_score:0.78865\n",
      "[6]\ttrain-merror:0.06583\ttrain-mlogloss:0.44255\ttrain-f1_score:0.91478\tval-merror:0.19624\tval-mlogloss:0.72460\tval-f1_score:0.79110\n",
      "[7]\ttrain-merror:0.06128\ttrain-mlogloss:0.38904\ttrain-f1_score:0.91982\tval-merror:0.19280\tval-mlogloss:0.68398\tval-f1_score:0.79564\n",
      "[8]\ttrain-merror:0.05726\ttrain-mlogloss:0.34520\ttrain-f1_score:0.92389\tval-merror:0.19168\tval-mlogloss:0.65206\tval-f1_score:0.79744\n",
      "[9]\ttrain-merror:0.05375\ttrain-mlogloss:0.30960\ttrain-f1_score:0.92832\tval-merror:0.18919\tval-mlogloss:0.62501\tval-f1_score:0.80090\n",
      "[10]\ttrain-merror:0.05006\ttrain-mlogloss:0.27973\ttrain-f1_score:0.93245\tval-merror:0.18558\tval-mlogloss:0.60373\tval-f1_score:0.80465\n",
      "[11]\ttrain-merror:0.04603\ttrain-mlogloss:0.25337\ttrain-f1_score:0.93749\tval-merror:0.18601\tval-mlogloss:0.58470\tval-f1_score:0.80488\n",
      "[12]\ttrain-merror:0.04314\ttrain-mlogloss:0.23099\ttrain-f1_score:0.94084\tval-merror:0.18316\tval-mlogloss:0.56986\tval-f1_score:0.80837\n",
      "[13]\ttrain-merror:0.03990\ttrain-mlogloss:0.21236\ttrain-f1_score:0.94523\tval-merror:0.18128\tval-mlogloss:0.56001\tval-f1_score:0.81107\n",
      "[14]\ttrain-merror:0.03721\ttrain-mlogloss:0.19559\ttrain-f1_score:0.94887\tval-merror:0.17999\tval-mlogloss:0.54965\tval-f1_score:0.81244\n",
      "[15]\ttrain-merror:0.03500\ttrain-mlogloss:0.18042\ttrain-f1_score:0.95113\tval-merror:0.17703\tval-mlogloss:0.54156\tval-f1_score:0.81627\n",
      "[16]\ttrain-merror:0.03235\ttrain-mlogloss:0.16816\ttrain-f1_score:0.95398\tval-merror:0.17645\tval-mlogloss:0.53473\tval-f1_score:0.81746\n",
      "[17]\ttrain-merror:0.03035\ttrain-mlogloss:0.15737\ttrain-f1_score:0.95670\tval-merror:0.17691\tval-mlogloss:0.52937\tval-f1_score:0.81761\n",
      "[18]\ttrain-merror:0.02813\ttrain-mlogloss:0.14669\ttrain-f1_score:0.95970\tval-merror:0.17468\tval-mlogloss:0.52565\tval-f1_score:0.81970\n",
      "[19]\ttrain-merror:0.02662\ttrain-mlogloss:0.13799\ttrain-f1_score:0.96172\tval-merror:0.17540\tval-mlogloss:0.52375\tval-f1_score:0.81980\n",
      "[20]\ttrain-merror:0.02482\ttrain-mlogloss:0.13010\ttrain-f1_score:0.96392\tval-merror:0.17558\tval-mlogloss:0.52106\tval-f1_score:0.81990\n",
      "[21]\ttrain-merror:0.02313\ttrain-mlogloss:0.12285\ttrain-f1_score:0.96581\tval-merror:0.17425\tval-mlogloss:0.51712\tval-f1_score:0.82158\n",
      "[22]\ttrain-merror:0.02203\ttrain-mlogloss:0.11635\ttrain-f1_score:0.96718\tval-merror:0.17378\tval-mlogloss:0.51570\tval-f1_score:0.82210\n",
      "[23]\ttrain-merror:0.02050\ttrain-mlogloss:0.10995\ttrain-f1_score:0.96898\tval-merror:0.17347\tval-mlogloss:0.51486\tval-f1_score:0.82249\n",
      "[24]\ttrain-merror:0.01924\ttrain-mlogloss:0.10492\ttrain-f1_score:0.97077\tval-merror:0.17283\tval-mlogloss:0.51352\tval-f1_score:0.82411\n",
      "[25]\ttrain-merror:0.01813\ttrain-mlogloss:0.09992\ttrain-f1_score:0.97219\tval-merror:0.17279\tval-mlogloss:0.51228\tval-f1_score:0.82465\n",
      "[26]\ttrain-merror:0.01744\ttrain-mlogloss:0.09535\ttrain-f1_score:0.97334\tval-merror:0.17304\tval-mlogloss:0.51186\tval-f1_score:0.82477\n",
      "[27]\ttrain-merror:0.01661\ttrain-mlogloss:0.09120\ttrain-f1_score:0.97459\tval-merror:0.17223\tval-mlogloss:0.51230\tval-f1_score:0.82596\n",
      "[28]\ttrain-merror:0.01558\ttrain-mlogloss:0.08726\ttrain-f1_score:0.97598\tval-merror:0.17202\tval-mlogloss:0.51326\tval-f1_score:0.82693\n",
      "[29]\ttrain-merror:0.01470\ttrain-mlogloss:0.08354\ttrain-f1_score:0.97706\tval-merror:0.17039\tval-mlogloss:0.51338\tval-f1_score:0.82836\n",
      "[30]\ttrain-merror:0.01417\ttrain-mlogloss:0.07996\ttrain-f1_score:0.97796\tval-merror:0.17065\tval-mlogloss:0.51378\tval-f1_score:0.82828\n",
      "[31]\ttrain-merror:0.01341\ttrain-mlogloss:0.07681\ttrain-f1_score:0.97898\tval-merror:0.17167\tval-mlogloss:0.51396\tval-f1_score:0.82782\n",
      "[32]\ttrain-merror:0.01278\ttrain-mlogloss:0.07376\ttrain-f1_score:0.97996\tval-merror:0.17145\tval-mlogloss:0.51461\tval-f1_score:0.82787\n",
      "[33]\ttrain-merror:0.01212\ttrain-mlogloss:0.07096\ttrain-f1_score:0.98074\tval-merror:0.17240\tval-mlogloss:0.51588\tval-f1_score:0.82755\n",
      "[34]\ttrain-merror:0.01138\ttrain-mlogloss:0.06847\ttrain-f1_score:0.98150\tval-merror:0.17140\tval-mlogloss:0.51721\tval-f1_score:0.82854\n",
      "[35]\ttrain-merror:0.01095\ttrain-mlogloss:0.06620\ttrain-f1_score:0.98210\tval-merror:0.17176\tval-mlogloss:0.51806\tval-f1_score:0.82892\n",
      "[36]\ttrain-merror:0.01053\ttrain-mlogloss:0.06374\ttrain-f1_score:0.98287\tval-merror:0.17051\tval-mlogloss:0.51901\tval-f1_score:0.83038\n",
      "[37]\ttrain-merror:0.01003\ttrain-mlogloss:0.06135\ttrain-f1_score:0.98354\tval-merror:0.17151\tval-mlogloss:0.52010\tval-f1_score:0.82985\n",
      "[38]\ttrain-merror:0.00947\ttrain-mlogloss:0.05927\ttrain-f1_score:0.98435\tval-merror:0.17078\tval-mlogloss:0.52151\tval-f1_score:0.83040\n",
      "[39]\ttrain-merror:0.00892\ttrain-mlogloss:0.05734\ttrain-f1_score:0.98515\tval-merror:0.17027\tval-mlogloss:0.52324\tval-f1_score:0.83162\n",
      "[40]\ttrain-merror:0.00810\ttrain-mlogloss:0.05537\ttrain-f1_score:0.98668\tval-merror:0.17113\tval-mlogloss:0.52367\tval-f1_score:0.83008\n",
      "[41]\ttrain-merror:0.00784\ttrain-mlogloss:0.05371\ttrain-f1_score:0.98709\tval-merror:0.17037\tval-mlogloss:0.52532\tval-f1_score:0.83178\n",
      "[42]\ttrain-merror:0.00730\ttrain-mlogloss:0.05210\ttrain-f1_score:0.98800\tval-merror:0.17056\tval-mlogloss:0.52552\tval-f1_score:0.83265\n",
      "[43]\ttrain-merror:0.00694\ttrain-mlogloss:0.05039\ttrain-f1_score:0.98834\tval-merror:0.17021\tval-mlogloss:0.52664\tval-f1_score:0.83300\n",
      "[44]\ttrain-merror:0.00676\ttrain-mlogloss:0.04886\ttrain-f1_score:0.98865\tval-merror:0.16996\tval-mlogloss:0.52885\tval-f1_score:0.83319\n",
      "[45]\ttrain-merror:0.00652\ttrain-mlogloss:0.04735\ttrain-f1_score:0.98890\tval-merror:0.16919\tval-mlogloss:0.53021\tval-f1_score:0.83362\n",
      "[46]\ttrain-merror:0.00629\ttrain-mlogloss:0.04606\ttrain-f1_score:0.98928\tval-merror:0.16899\tval-mlogloss:0.53145\tval-f1_score:0.83403\n",
      "[47]\ttrain-merror:0.00599\ttrain-mlogloss:0.04468\ttrain-f1_score:0.98973\tval-merror:0.16913\tval-mlogloss:0.53359\tval-f1_score:0.83393\n",
      "[48]\ttrain-merror:0.00582\ttrain-mlogloss:0.04338\ttrain-f1_score:0.99011\tval-merror:0.16867\tval-mlogloss:0.53459\tval-f1_score:0.83439\n",
      "[49]\ttrain-merror:0.00558\ttrain-mlogloss:0.04214\ttrain-f1_score:0.99045\tval-merror:0.16823\tval-mlogloss:0.53583\tval-f1_score:0.83543\n",
      "[50]\ttrain-merror:0.00541\ttrain-mlogloss:0.04102\ttrain-f1_score:0.99074\tval-merror:0.16845\tval-mlogloss:0.53794\tval-f1_score:0.83585\n",
      "[51]\ttrain-merror:0.00515\ttrain-mlogloss:0.03980\ttrain-f1_score:0.99107\tval-merror:0.16860\tval-mlogloss:0.54028\tval-f1_score:0.83618\n",
      "[52]\ttrain-merror:0.00500\ttrain-mlogloss:0.03877\ttrain-f1_score:0.99141\tval-merror:0.16775\tval-mlogloss:0.54210\tval-f1_score:0.83735\n",
      "[53]\ttrain-merror:0.00481\ttrain-mlogloss:0.03761\ttrain-f1_score:0.99169\tval-merror:0.16770\tval-mlogloss:0.54364\tval-f1_score:0.83761\n",
      "[54]\ttrain-merror:0.00469\ttrain-mlogloss:0.03659\ttrain-f1_score:0.99183\tval-merror:0.16700\tval-mlogloss:0.54567\tval-f1_score:0.83827\n",
      "[55]\ttrain-merror:0.00456\ttrain-mlogloss:0.03544\ttrain-f1_score:0.99202\tval-merror:0.16786\tval-mlogloss:0.54685\tval-f1_score:0.83760\n",
      "[56]\ttrain-merror:0.00437\ttrain-mlogloss:0.03443\ttrain-f1_score:0.99239\tval-merror:0.16766\tval-mlogloss:0.54926\tval-f1_score:0.83806\n",
      "[57]\ttrain-merror:0.00421\ttrain-mlogloss:0.03354\ttrain-f1_score:0.99264\tval-merror:0.16772\tval-mlogloss:0.55099\tval-f1_score:0.83857\n",
      "[58]\ttrain-merror:0.00415\ttrain-mlogloss:0.03270\ttrain-f1_score:0.99281\tval-merror:0.16738\tval-mlogloss:0.55297\tval-f1_score:0.83867\n",
      "[59]\ttrain-merror:0.00403\ttrain-mlogloss:0.03187\ttrain-f1_score:0.99303\tval-merror:0.16728\tval-mlogloss:0.55407\tval-f1_score:0.83923\n",
      "[60]\ttrain-merror:0.00390\ttrain-mlogloss:0.03112\ttrain-f1_score:0.99313\tval-merror:0.16762\tval-mlogloss:0.55549\tval-f1_score:0.83888\n",
      "[61]\ttrain-merror:0.00381\ttrain-mlogloss:0.03032\ttrain-f1_score:0.99324\tval-merror:0.16753\tval-mlogloss:0.55761\tval-f1_score:0.83892\n",
      "[62]\ttrain-merror:0.00366\ttrain-mlogloss:0.02963\ttrain-f1_score:0.99343\tval-merror:0.16827\tval-mlogloss:0.55912\tval-f1_score:0.83869\n",
      "[63]\ttrain-merror:0.00356\ttrain-mlogloss:0.02900\ttrain-f1_score:0.99360\tval-merror:0.16917\tval-mlogloss:0.56019\tval-f1_score:0.83751\n",
      "[64]\ttrain-merror:0.00339\ttrain-mlogloss:0.02830\ttrain-f1_score:0.99396\tval-merror:0.16896\tval-mlogloss:0.56220\tval-f1_score:0.83805\n",
      "[65]\ttrain-merror:0.00331\ttrain-mlogloss:0.02759\ttrain-f1_score:0.99416\tval-merror:0.16843\tval-mlogloss:0.56388\tval-f1_score:0.83858\n",
      "[66]\ttrain-merror:0.00309\ttrain-mlogloss:0.02683\ttrain-f1_score:0.99435\tval-merror:0.16777\tval-mlogloss:0.56695\tval-f1_score:0.83912\n",
      "[67]\ttrain-merror:0.00302\ttrain-mlogloss:0.02624\ttrain-f1_score:0.99453\tval-merror:0.16749\tval-mlogloss:0.56845\tval-f1_score:0.83959\n",
      "[68]\ttrain-merror:0.00302\ttrain-mlogloss:0.02557\ttrain-f1_score:0.99461\tval-merror:0.16894\tval-mlogloss:0.57054\tval-f1_score:0.83791\n",
      "[69]\ttrain-merror:0.00301\ttrain-mlogloss:0.02505\ttrain-f1_score:0.99469\tval-merror:0.16940\tval-mlogloss:0.57226\tval-f1_score:0.83798\n",
      "[70]\ttrain-merror:0.00292\ttrain-mlogloss:0.02449\ttrain-f1_score:0.99486\tval-merror:0.16823\tval-mlogloss:0.57342\tval-f1_score:0.83905\n",
      "[71]\ttrain-merror:0.00278\ttrain-mlogloss:0.02392\ttrain-f1_score:0.99505\tval-merror:0.16812\tval-mlogloss:0.57552\tval-f1_score:0.83923\n",
      "[72]\ttrain-merror:0.00264\ttrain-mlogloss:0.02332\ttrain-f1_score:0.99518\tval-merror:0.16807\tval-mlogloss:0.57781\tval-f1_score:0.83907\n",
      "[73]\ttrain-merror:0.00263\ttrain-mlogloss:0.02284\ttrain-f1_score:0.99529\tval-merror:0.16822\tval-mlogloss:0.58009\tval-f1_score:0.83916\n",
      "[74]\ttrain-merror:0.00256\ttrain-mlogloss:0.02235\ttrain-f1_score:0.99543\tval-merror:0.16829\tval-mlogloss:0.58191\tval-f1_score:0.83945\n",
      "[75]\ttrain-merror:0.00249\ttrain-mlogloss:0.02188\ttrain-f1_score:0.99550\tval-merror:0.16876\tval-mlogloss:0.58388\tval-f1_score:0.83928\n",
      "[76]\ttrain-merror:0.00241\ttrain-mlogloss:0.02140\ttrain-f1_score:0.99569\tval-merror:0.16900\tval-mlogloss:0.58608\tval-f1_score:0.83915\n",
      "[77]\ttrain-merror:0.00235\ttrain-mlogloss:0.02097\ttrain-f1_score:0.99575\tval-merror:0.16932\tval-mlogloss:0.58838\tval-f1_score:0.83883\n",
      "[78]\ttrain-merror:0.00232\ttrain-mlogloss:0.02054\ttrain-f1_score:0.99581\tval-merror:0.16991\tval-mlogloss:0.58970\tval-f1_score:0.83821\n",
      "[79]\ttrain-merror:0.00225\ttrain-mlogloss:0.02011\ttrain-f1_score:0.99592\tval-merror:0.17069\tval-mlogloss:0.59172\tval-f1_score:0.83765\n",
      "[80]\ttrain-merror:0.00219\ttrain-mlogloss:0.01972\ttrain-f1_score:0.99603\tval-merror:0.17101\tval-mlogloss:0.59350\tval-f1_score:0.83749\n",
      "[81]\ttrain-merror:0.00219\ttrain-mlogloss:0.01934\ttrain-f1_score:0.99605\tval-merror:0.17036\tval-mlogloss:0.59499\tval-f1_score:0.83823\n",
      "[82]\ttrain-merror:0.00218\ttrain-mlogloss:0.01895\ttrain-f1_score:0.99613\tval-merror:0.17022\tval-mlogloss:0.59636\tval-f1_score:0.83837\n",
      "[83]\ttrain-merror:0.00211\ttrain-mlogloss:0.01859\ttrain-f1_score:0.99622\tval-merror:0.16975\tval-mlogloss:0.59788\tval-f1_score:0.83933\n",
      "[84]\ttrain-merror:0.00208\ttrain-mlogloss:0.01819\ttrain-f1_score:0.99632\tval-merror:0.16981\tval-mlogloss:0.60066\tval-f1_score:0.83929\n",
      "[85]\ttrain-merror:0.00200\ttrain-mlogloss:0.01787\ttrain-f1_score:0.99647\tval-merror:0.16917\tval-mlogloss:0.60213\tval-f1_score:0.83972\n",
      "[86]\ttrain-merror:0.00200\ttrain-mlogloss:0.01753\ttrain-f1_score:0.99649\tval-merror:0.16843\tval-mlogloss:0.60403\tval-f1_score:0.84062\n",
      "[87]\ttrain-merror:0.00196\ttrain-mlogloss:0.01717\ttrain-f1_score:0.99653\tval-merror:0.16889\tval-mlogloss:0.60613\tval-f1_score:0.84023\n",
      "[88]\ttrain-merror:0.00192\ttrain-mlogloss:0.01683\ttrain-f1_score:0.99666\tval-merror:0.16991\tval-mlogloss:0.60752\tval-f1_score:0.83911\n",
      "[89]\ttrain-merror:0.00182\ttrain-mlogloss:0.01647\ttrain-f1_score:0.99682\tval-merror:0.16961\tval-mlogloss:0.60955\tval-f1_score:0.83928\n",
      "[90]\ttrain-merror:0.00178\ttrain-mlogloss:0.01613\ttrain-f1_score:0.99690\tval-merror:0.17054\tval-mlogloss:0.61157\tval-f1_score:0.83814\n",
      "[91]\ttrain-merror:0.00174\ttrain-mlogloss:0.01582\ttrain-f1_score:0.99697\tval-merror:0.16969\tval-mlogloss:0.61327\tval-f1_score:0.83918\n",
      "[92]\ttrain-merror:0.00164\ttrain-mlogloss:0.01552\ttrain-f1_score:0.99715\tval-merror:0.16966\tval-mlogloss:0.61538\tval-f1_score:0.83929\n",
      "[93]\ttrain-merror:0.00158\ttrain-mlogloss:0.01526\ttrain-f1_score:0.99725\tval-merror:0.16948\tval-mlogloss:0.61731\tval-f1_score:0.83958\n",
      "[94]\ttrain-merror:0.00152\ttrain-mlogloss:0.01486\ttrain-f1_score:0.99733\tval-merror:0.17070\tval-mlogloss:0.61945\tval-f1_score:0.83827\n",
      "[95]\ttrain-merror:0.00149\ttrain-mlogloss:0.01459\ttrain-f1_score:0.99738\tval-merror:0.17175\tval-mlogloss:0.62095\tval-f1_score:0.83735\n",
      "[96]\ttrain-merror:0.00148\ttrain-mlogloss:0.01434\ttrain-f1_score:0.99743\tval-merror:0.17141\tval-mlogloss:0.62248\tval-f1_score:0.83757\n",
      "[97]\ttrain-merror:0.00144\ttrain-mlogloss:0.01408\ttrain-f1_score:0.99752\tval-merror:0.17158\tval-mlogloss:0.62430\tval-f1_score:0.83741\n",
      "[98]\ttrain-merror:0.00140\ttrain-mlogloss:0.01380\ttrain-f1_score:0.99759\tval-merror:0.17147\tval-mlogloss:0.62577\tval-f1_score:0.83769\n",
      "[99]\ttrain-merror:0.00140\ttrain-mlogloss:0.01358\ttrain-f1_score:0.99755\tval-merror:0.17104\tval-mlogloss:0.62739\tval-f1_score:0.83791\n"
     ]
    }
   ],
   "source": [
    "# debugging:\n",
    "\n",
    "def custom_eval_f1_avg(y_pred, y_true):\n",
    "    global f1_scores\n",
    "    y_true = y_true.get_label()\n",
    "    f1 = f1_score(y_true, np.argmax(y_pred, axis=1), average=None)\n",
    "    f1_avg = f1_score(y_true, np.argmax(y_pred, axis=1), average='macro')\n",
    "    # appends train f1-score, then val f1-score, and so forth\n",
    "    # we're storing it in global variable \"f1_scores\", as xgboost library doesn't accept custom eval function which returns a list (like f1-score metric)\n",
    "    # you just have to initialize a variable \"f1_scores\" as empty list before calling any xgb.train() in this notebook\n",
    "    f1_scores.append(f1)\n",
    "    return 'f1_score', f1_avg\n",
    "\n",
    "# read data\n",
    "X_train = imgTrainFeatures \n",
    "y_train = [classNameToNum[className] for className in train_data['label']]\n",
    "X_val = imgValFeatures\n",
    "y_val = [classNameToNum[className] for className in val_data['label']]\n",
    "X_test = imgTestFeatures\n",
    "y_test = [classNameToNum[className] for className in test_data['label']]\n",
    "# create model instance\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "# mlogloss <==> cross-entropy loss\n",
    "# merror <==> 1 - accuracy (i.e., ratio of misclassified labels over all #classifications)\n",
    "# Side-note: if you'll pass a custom function to eval_metric, then it should return a tuple of string (e.g., 'f1_score_avg') and value (single value, not a list of values).\n",
    "# Also, if you pass a custom function, then you can't pass any other metrics (i.e., eval_metric=func_name , NOT eval_metric=[func_name, 'mlogloss', ...])\n",
    "# bst = XGBClassifier(n_estimators=10, eval_metric=[\"mlogloss\", \"merror\"], objective='multi:softprob', random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(\n",
    "    data = X_train,\n",
    "    label = y_train,\n",
    "    weight = class_weight.compute_sample_weight(class_weight='balanced',y = y_train)\n",
    ")\n",
    "\n",
    "dval = xgb.DMatrix(\n",
    "    data = X_val,\n",
    "    label = y_val,\n",
    "    weight = class_weight.compute_sample_weight(class_weight='balanced',y = y_val)\n",
    ")\n",
    "\n",
    "dtest = xgb.DMatrix(\n",
    "    data = X_test,\n",
    "    label = y_test,\n",
    "    weight = class_weight.compute_sample_weight(class_weight='balanced',y = y_test)\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'booster' : 'gbtree', \n",
    "    'learning_rate' : 0.3, # alternatively, 'eta'\n",
    "    'max_depth' : 6,\n",
    "    'min_child_weight' : 1,\n",
    "    # doesn't work, you have to pass it in xgb.train()\n",
    "    # 'early_stopping_rounds':3,\n",
    "\n",
    "    'seed' : 42,\n",
    "    'verbosity' : 1,\n",
    "    # by default, uses all available threads (I think)\n",
    "    # 'nthread' : 4,\n",
    "    'num_class' : 9,\n",
    "    'objective' : 'multi:softprob',\n",
    "    # in 'eval_metric', if early_stopping is applied, then the last metric will be the one considered\n",
    "    # however, if you pass a custom metric (in xgb.train()), then that will always be chosen by early stopping\n",
    "    # also, you can't call a custom function in eval_metric's list of metrics; it has to be in xgb.train()\n",
    "    'eval_metric' : ['merror', 'mlogloss'] \n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')] # if early_stopping is applied, then the last data set will be the one considered\n",
    "n_rounds = 100\n",
    "results = {}\n",
    "# regarding early stopping (from xgb.train()'s docstring):\n",
    "# The method returns the model from the last iteration (not the best one). \n",
    "# Use custom callback or model slicing if the best model is desired.\n",
    "f1_scores = []\n",
    "\n",
    "\n",
    "bst = xgb.train(params, dtrain, n_rounds, evals=watchlist, evals_result=results, custom_metric=custom_eval_f1_avg, early_stopping_rounds=0)\n",
    "\n",
    "# make predictions\n",
    "preds = bst.predict(dtest, output_margin=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 1., 1.]),\n",
       " array([1., 1., 1.]),\n",
       " array([1., 1., 1.]),\n",
       " array([1., 1., 1.])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# debugging:\n",
    "# f1_scores[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'modelNumber', 'loss', 'acc', 'f1_score', 'val_loss', 'val_acc', 'val_f1_score', 'test_loss', 'test_acc', 'test_f1_score', 'test_support', 'test_yTrue', 'test_yPred', 'test_confusion_matrix', 'test_confusion_matrix_normalized'])\n"
     ]
    }
   ],
   "source": [
    "# debugging:\n",
    "epochs_num = len(results[\"train\"][\"mlogloss\"])\n",
    "model_version = '04'\n",
    "results['train']['f1_score'] = f1_scores[0::2]\n",
    "results['val']['f1_score'] = f1_scores[1::2]\n",
    "history = {\n",
    "    'epoch' : [i for i in range(epochs_num)],\n",
    "    'modelNumber': model_version,\n",
    "    'loss': np.array(results[\"train\"][\"mlogloss\"]),\n",
    "    'acc': np.array(list(map(lambda x : 1 - x, results[\"train\"][\"merror\"]))).round(5),\n",
    "    'f1_score': np.array(results[\"train\"][\"f1_score\"]).round(5),\n",
    "    'val_loss': np.array(results[\"val\"][\"mlogloss\"]),\n",
    "    'val_acc': np.array(list(map(lambda x : 1 - x, results[\"val\"][\"merror\"]))).round(5),\n",
    "    'val_f1_score': np.array(results[\"train\"][\"f1_score\"]).round(5),\n",
    "}\n",
    "\n",
    "history.update(getMetrics(y_test, preds, list(classNameToNum.keys())))\n",
    "print(history.keys())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
