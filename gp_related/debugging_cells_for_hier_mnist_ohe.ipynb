{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | conv1    | Conv2d     | 320   \n",
      "1 | conv2    | Conv2d     | 18.5 K\n",
      "2 | dropout1 | Dropout2d  | 0     \n",
      "3 | dropout2 | Dropout2d  | 0     \n",
      "4 | fc1      | LazyLinear | 0     \n",
      "5 | fc2      | LazyLinear | 0     \n",
      "----------------------------------------\n",
      "18.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.8 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa75e9fda9f4d3e83cb1068e4913db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CS\\projects\\graduation_project\\.mamba\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Union\n",
    "from pytorch_lightning.utilities.types import EPOCH_OUTPUT\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "class MNISTClassifier(pl.LightningModule):\n",
    "    def __init__(self, the_device='cuda', num_classes=10, dummy_input_size=(32,3,306,306)):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.LazyLinear(128)\n",
    "        self.fc2 = nn.LazyLinear(10)\n",
    "        \n",
    "        # useful for writing computational graph in tensorboard, summary(), etc\n",
    "        # self.example_input_array = torch.randn(*dummy_input_size) \n",
    "\n",
    "        self.the_device = the_device\n",
    "\n",
    "        def _create_metric_func(metric_type:str):\n",
    "            if 'acc' in metric_type.lower():\n",
    "                return torchmetrics.Accuracy(task='multiclass', \n",
    "                                             num_classes=num_classes, \n",
    "                                             average=\"micro\").to(the_device)\n",
    "            elif 'f1' in metric_type.lower():\n",
    "                return torchmetrics.F1Score(task=\"multiclass\", \n",
    "                                            num_classes=num_classes, \n",
    "                                            average=None).to(the_device)\n",
    "        \n",
    "        # for calculating metric of a step\n",
    "        self.acc_step_funcs = [_create_metric_func('acc') for _ in range(3)] # for computing train, val, test results respectively\n",
    "        self.f1_score_step_funcs = [_create_metric_func('f1') for _ in range(3)]\n",
    "        # for calculating metric of an epoch\n",
    "        self.acc_epoch_funcs = [_create_metric_func('acc') for _ in range(3)]\n",
    "        self.f1_score_epoch_funcs = [_create_metric_func('f1') for _ in range(3)]\n",
    "        \n",
    "        self.history = {\n",
    "            # per epoch\n",
    "            'loss':[],\n",
    "            'acc':[],\n",
    "            'f1_score':[],\n",
    "            'val_loss':[],\n",
    "            'val_acc':[],\n",
    "            'val_f1_score':[],\n",
    "            'test_loss':[],\n",
    "            'test_acc':[],\n",
    "            'test_f1_score':[],\n",
    "            # per step\n",
    "            'step_loss':[],\n",
    "            'step_acc':[],\n",
    "            'step_f1_score':[],\n",
    "            'val_step_loss':[],\n",
    "            'val_step_acc':[],\n",
    "            'val_step_f1_score':[],\n",
    "            'test_step_loss':[],\n",
    "            'test_step_acc':[],\n",
    "            'test_step_f1_score':[],\n",
    "            # for tracking pred/true values for train/val/test sets\n",
    "            'step_y_pred': [],\n",
    "            'step_y_true': [],\n",
    "            'val_step_y_pred': [],\n",
    "            'val_step_y_true': [],\n",
    "            'test_step_y_pred': [],\n",
    "            'test_step_y_true': [],\n",
    "        }\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "    def _store_metric(self, metric_name, metric_val):\n",
    "        try:\n",
    "            self.log(metric_name, metric_val)\n",
    "        except Exception as e:\n",
    "            # then metric_val is not scalar, then this means:\n",
    "            # metric_name is an f1 score metric \n",
    "            # so, we just take the mean value\n",
    "            self.log(metric_name, metric_val.mean())\n",
    "        # putting this here ensures we don't include the mean of f1 score, \n",
    "        # but rather the tensor of shape (1, num_classes)\n",
    "        self.history[metric_name].append(metric_val)\n",
    "\n",
    "    def _step_logic(self, batch, prefix=''):\n",
    "        if 'val' in prefix:\n",
    "            func_idx = 1\n",
    "        elif 'test' in prefix:\n",
    "            func_idx = 2\n",
    "        else:\n",
    "            func_idx = 0\n",
    "        \n",
    "        x, y_true = batch\n",
    "        y_pred = self(x)\n",
    "        # log step metrics\n",
    "        loss = F.cross_entropy(y_pred, y_true)\n",
    "        self._store_metric(f'{prefix}step_loss', loss)\n",
    "\n",
    "        acc = self.acc_step_funcs[func_idx](y_pred, y_true)\n",
    "        self._store_metric(f'{prefix}step_acc', acc)\n",
    "        self.acc_epoch_funcs[func_idx].update(y_pred, y_true)\n",
    "    \n",
    "        f1_score = self.f1_score_step_funcs[func_idx](y_pred, y_true)\n",
    "        self._store_metric(f'{prefix}step_f1_score', f1_score)\n",
    "        self.f1_score_epoch_funcs[func_idx].update(y_pred, y_true)\n",
    "\n",
    "        # storing y_pred/y_true\n",
    "        self.history[f'{prefix}step_y_pred'].extend(y_pred)\n",
    "        self.history[f'{prefix}step_y_true'].extend(y_true)\n",
    "\n",
    "        return loss, acc, f1_score\n",
    "    \n",
    "    def _epoch_end_logic(self, outs, prefix=''):\n",
    "        if 'val' in prefix:\n",
    "            func_idx = 1\n",
    "        elif 'test' in prefix:\n",
    "            func_idx = 2\n",
    "        else:\n",
    "            func_idx = 0\n",
    "\n",
    "        # log epoch metrics\n",
    "        loss_epoch = torch.tensor([x[f'{prefix}loss'] for x in outs], dtype=float).mean()\n",
    "        self._store_metric(f'{prefix}loss', loss_epoch)\n",
    "\n",
    "        acc_epoch = self.acc_epoch_funcs[func_idx].compute()\n",
    "        self.acc_epoch_funcs[func_idx].reset()\n",
    "        self._store_metric(f'{prefix}acc', acc_epoch)\n",
    "\n",
    "        f1_score_epoch = self.f1_score_epoch_funcs[func_idx].compute()\n",
    "        self.f1_score_epoch_funcs[func_idx].reset()\n",
    "        self._store_metric(f'{prefix}f1_score', f1_score_epoch)\n",
    "\n",
    "        return loss_epoch, acc_epoch, f1_score_epoch\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        prefix = ''\n",
    "        loss, acc, f1_score = self._step_logic(batch, prefix=prefix)\n",
    "        return {f'{prefix}loss':loss, f'{prefix}acc':acc, f'{prefix}f1_score':f1_score}\n",
    "    \n",
    "    def training_epoch_end(self, outs) -> None:\n",
    "        # 'outs' argument here contains values from what was returned from training_step()\n",
    "        _,_,_ = self._epoch_end_logic(outs)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        prefix = 'val_'\n",
    "        loss, acc, f1_score = self._step_logic(batch, prefix=prefix)\n",
    "        return {f'{prefix}loss':loss, f'{prefix}acc':acc, f'{prefix}f1_score':f1_score}\n",
    "\n",
    "    def validation_epoch_end(self, outs) -> None:\n",
    "        _,_,_ = self._epoch_end_logic(outs, prefix='val_')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        prefix = 'test_'\n",
    "        loss, acc, f1_score = self._step_logic(batch, prefix=prefix)\n",
    "        return {f'{prefix}loss':loss, f'{prefix}acc':acc, f'{prefix}f1_score':f1_score}\n",
    "\n",
    "    def test_epoch_end(self, outs) -> None:\n",
    "        _,_,_ = self._epoch_end_logic(outs, prefix='test_')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# init the autoencoder\n",
    "cnnLightning = MNISTClassifier(the_device='cuda')\n",
    "# setup data\n",
    "dataset = MNIST(os.getcwd(), download=True, transform=ToTensor())\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [50000, 10000])\n",
    "train_loader = utils.data.DataLoader(train_dataset, batch_size=32, num_workers=4)\n",
    "val_loader = utils.data.DataLoader(val_dataset, batch_size=32, num_workers=4)\n",
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "trainer = pl.Trainer(log_every_n_steps=1, num_sanity_val_steps=0, max_epochs=3, accelerator='gpu', fast_dev_run=False)\n",
    "trainer.fit(model=cnnLightning, train_dataloaders=train_loader, val_dataloaders=val_loader) # , val_dataloaders=val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.model.history.copy()\n",
    "for metric, tensors_list in history.items():\n",
    "    if isinstance(tensors_list, list) and len(tensors_list) > 0 and isinstance(tensors_list[0], torch.Tensor):\n",
    "        history[metric] = np.array([np.array(tens.detach().cpu()) for tens in tensors_list]).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.5039, 0.4961],\n",
       "         [0.5040, 0.4960],\n",
       "         [0.5040, 0.4960],\n",
       "         [0.5040, 0.4960]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.2513, 0.2444, 0.2263, 0.2780],\n",
       "         [0.2514, 0.2444, 0.2262, 0.2780],\n",
       "         [0.2513, 0.2444, 0.2263, 0.2780],\n",
       "         [0.2513, 0.2444, 0.2262, 0.2780]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.2561, 0.2539, 0.2301, 0.2599],\n",
       "         [0.2561, 0.2538, 0.2302, 0.2599],\n",
       "         [0.2561, 0.2538, 0.2301, 0.2599],\n",
       "         [0.2561, 0.2539, 0.2301, 0.2599]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.3410, 0.3629, 0.2960],\n",
       "         [0.3410, 0.3629, 0.2961],\n",
       "         [0.3410, 0.3629, 0.2960],\n",
       "         [0.3410, 0.3630, 0.2960]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.3407, 0.3076, 0.3518],\n",
       "         [0.3407, 0.3075, 0.3518],\n",
       "         [0.3407, 0.3075, 0.3518],\n",
       "         [0.3407, 0.3075, 0.3517]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.3223, 0.3448, 0.3329],\n",
       "         [0.3223, 0.3448, 0.3329],\n",
       "         [0.3223, 0.3449, 0.3329],\n",
       "         [0.3223, 0.3449, 0.3328]], grad_fn=<SoftmaxBackward0>)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# debugging cell: dummy example for demonstration purposes:\n",
    "# the code in this cell can be found in forward()\n",
    "\n",
    "# len(hier_y_probs) == num_hierarchy_output_layers, \n",
    "# while each element is 2D tensor of shape (batch_size, num_classes of the i_th output layer in hierarchy)\n",
    "hier_y_pred = []\n",
    "for tensor_output in demo_model(a):\n",
    "    hier_y_pred.append(F.softmax(tensor_output, dim=1))\n",
    "hier_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 3, 2, 2, 2],\n",
      "        [0, 1, 3, 0, 2, 2],\n",
      "        [0, 1, 3, 1, 2, 2],\n",
      "        [1, 3, 0, 2, 0, 2]])\n",
      "tensor([[0, 0, 0, 1],\n",
      "        [0, 1, 1, 3],\n",
      "        [3, 3, 3, 0],\n",
      "        [2, 0, 1, 2],\n",
      "        [2, 2, 2, 0],\n",
      "        [2, 2, 2, 2]])\n",
      "\n",
      "tensor([0, 0, 0, 1])\n",
      "tensor([[0.5039, 0.4961],\n",
      "        [0.5040, 0.4960],\n",
      "        [0.5040, 0.4960],\n",
      "        [0.5040, 0.4960]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# debugging cell: dummy example for demonstration purposes:\n",
    "# the code in this cell can be found in train_step() (or actually, in _step_logic())\n",
    "\n",
    "# x, y = batch\n",
    "# hier_y_pred = self(x)\n",
    "y = torch.tensor([1,2,5,8]) # remove this in train_step()\n",
    "# y now has shape (batch_size, len(hier_y_pred))\n",
    "# in other words, each row now consists of `len(hier_y_pred)` output layers' labels of 1 sample\n",
    "y = torch.tensor([labelToHierarchy[i] for i in range(len(y))], dtype=int) # alternatively, range(y.size()[0])\n",
    "print(y)\n",
    "# transpose y to take each row (batch of labels) with its corresponding hier_y_pred row (batch of predicted labels)\n",
    "# in other words, each row now consists of `batch_size` labels of the i_th output layer\n",
    "y = y.T\n",
    "print(y)\n",
    "print()\n",
    "# softmax_output_layer elements each has shape (batch_size, num_classes of the i_th output layer in hierarchy)\n",
    "# side note: the wording of \"i_th output layers\" refers to the strings mentioned in \n",
    "# output_order argument of HierarchalModel() used in create_hnn_model_arch()\n",
    "for i, softmax_output_layer in enumerate(hier_y_pred):\n",
    "    # 'cur' refers to current output layer\n",
    "    y_cur = y[i]\n",
    "    y_pred_cur = softmax_output_layer\n",
    "    print(y_cur)\n",
    "    print(y_pred_cur)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function would've been useful if in training_step(), we returned 'y' as ohe (e.g., [0,0,1]) instead of integer labels (e.g., 2)\n",
    "def ohe(value, size): # ohe == one hot encode\n",
    "    identity = torch.eye(size)\n",
    "    one_hot = identity[value]\n",
    "    if (value == -1):\n",
    "        # then we want the ohe list to be all zeros\n",
    "        one_hot[-1] = 0\n",
    "    # uncomment this line if you want to return 2D tensor of shape (1, size)\n",
    "    # return one_hot.view(-1, size)\n",
    "    return one_hot\n",
    "\n",
    "classToHierarchy = {\n",
    "    '00. selfies' : [ohe(0, 2), # diversity of colors: many or few\n",
    "                     ohe(0, 4), # many colors: selfies, memes (fmm or emm), or eGreetingsAndMisc (+1 if none of them)\n",
    "                     ohe(-1, 4), # few colors: socialMedia (fsm or esm), fTxtMssgs, academic (photos or digital) (+1 if none of them)\n",
    "                     ohe(-1, 3), # meme type: fmm or emm (+1 if none of them)\n",
    "                     ohe(-1, 3), # social media type: fsm or esm (+1 if none of them)\n",
    "                     ohe(-1, 3)], # academic type: photos or digital (+1 if none of them)\n",
    "    '10. fmemes' : [ohe(0, 2), ohe(1, 4), ohe(-1, 4), ohe(0, 3), ohe(-1, 3), ohe(-1, 3)],\n",
    "    '20. ememes' : [ohe(0, 2), ohe(1, 4), ohe(-1, 4), ohe(1, 3), ohe(-1, 3), ohe(-1, 3)],\n",
    "    '30. fSocialMedia' : [ohe(1, 2), ohe(-1, 4), ohe(0, 4), ohe(-1, 3), ohe(0, 3), ohe(-1, 3)],\n",
    "    '40. eSocialMedia' : [ohe(1, 2), ohe(-1, 4), ohe(0, 4), ohe(-1, 3), ohe(1, 3), ohe(-1, 3)],\n",
    "    '50. fTxtMssgs' : [ohe(1, 2), ohe(-1, 4), ohe(1, 4), ohe(-1, 3), ohe(-1, 3), ohe(-1, 3)],\n",
    "    '70. eGreetingAndMisc' : [ohe(0, 2), ohe(2, 4), ohe(-1, 4), ohe(-1, 3), ohe(-1, 3), ohe(-1, 3)],\n",
    "    '81. academicPhotos' : [ohe(1, 2), ohe(-1, 4), ohe(2, 4), ohe(-1, 3), ohe(-1, 3), ohe(0, 3)],\n",
    "    '82. academicDigital' : [ohe(1, 2), ohe(-1, 4), ohe(2, 4), ohe(-1, 3), ohe(-1, 3), ohe(1, 3)],\n",
    "}\n",
    "classToHierarchy['00. selfies']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
